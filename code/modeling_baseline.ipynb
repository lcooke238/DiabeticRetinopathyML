{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modeling with Smaller Images\n",
    "I wanted to try working with the images pre-noise reduction (just grayscale and high contrast) to see if there are additional features of interest beyond the veins themselves that my image processing would have eliminated.\n",
    "\n",
    "After doing this, we get a baseline accuracy of about 75%, with a sensitivity of 77.2% and a specificity of 74.6%. This gives us an idea of how much room there is to improve using proper image preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 15:38:24.454912: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 15:38:29.072984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# load data\n",
    "Xtrainb = np.load(\"../data/train/Xtrainnew3.npy\")\n",
    "Ytrainb = np.load(\"../data/train/Ytrainnew3.npy\")\n",
    "Xtestb = np.load(\"../data/test/Xtestnew3.npy\")\n",
    "Ytestb = np.load(\"../data/test/Ytestnew3.npy\")\n",
    "\n",
    "# setup CNN using Inception-v3 (using google JAMA paper for this choice)\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=Xtrainb.shape[1:]\n",
    ")\n",
    "# freeze inceptionv3 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add additional layers to iterate on\n",
    "inputs = tf.keras.Input(shape=Xtrainb.shape[1:])\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x) #sumarizing feature existence rather than location\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "modelb = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# add some training callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n",
    "# Reducing the Learning Rate if result is not improving. \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "111/111 [==============================] - 55s 475ms/step - loss: 1.0022 - auc_1: 0.5744 - val_loss: 0.4291 - val_auc_1: 0.6435 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "111/111 [==============================] - 55s 494ms/step - loss: 0.4384 - auc_1: 0.6306 - val_loss: 0.4324 - val_auc_1: 0.6211 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "111/111 [==============================] - ETA: 0s - loss: 0.4882 - auc_1: 0.5977\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "111/111 [==============================] - 50s 451ms/step - loss: 0.4882 - auc_1: 0.5977 - val_loss: 0.4556 - val_auc_1: 0.6048 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "111/111 [==============================] - 49s 446ms/step - loss: 0.3902 - auc_1: 0.6543 - val_loss: 0.4256 - val_auc_1: 0.5870 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.3786 - auc_1: 0.6610 - val_loss: 0.4167 - val_auc_1: 0.6233 - lr: 1.0000e-04\n",
      "Epoch 6/60\n",
      "111/111 [==============================] - 49s 442ms/step - loss: 0.3788 - auc_1: 0.6681 - val_loss: 0.4262 - val_auc_1: 0.6402 - lr: 1.0000e-04\n",
      "Epoch 7/60\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.3841 - auc_1: 0.6602 - val_loss: 0.4133 - val_auc_1: 0.6184 - lr: 1.0000e-04\n",
      "Epoch 8/60\n",
      "111/111 [==============================] - 49s 444ms/step - loss: 0.3820 - auc_1: 0.6505 - val_loss: 0.4204 - val_auc_1: 0.5909 - lr: 1.0000e-04\n",
      "Epoch 9/60\n",
      "111/111 [==============================] - ETA: 0s - loss: 0.3787 - auc_1: 0.6648\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.3787 - auc_1: 0.6648 - val_loss: 0.4246 - val_auc_1: 0.6449 - lr: 1.0000e-04\n",
      "Epoch 10/60\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.3689 - auc_1: 0.6587 - val_loss: 0.4175 - val_auc_1: 0.6359 - lr: 1.0000e-05\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa73e327790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and save\n",
    "# train\n",
    "modelb.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.AUC()])\n",
    "modelb.fit(x=Xtrainb, y=Ytrainb, epochs=60, validation_data=(Xtestb, Ytestb), callbacks = [early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "modelb.save(\"../data/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887/887 [==============================] - 21s 23ms/step\n",
      "accuracy: 0.7497181510710259\n",
      "Sensitivity: 0.22695035460992907\n",
      "Specificity: 0.2546916890080429\n"
     ]
    }
   ],
   "source": [
    "# raw accuracy\n",
    "y_pred = modelb.predict(Xtestb, batch_size=1)\n",
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if np.round(y_pred[i]) == np.round(Ytestb[i]):\n",
    "        accuracy += 1\n",
    "print(f\"accuracy: {1-(accuracy/len(y_pred))}\")\n",
    "\n",
    "# get sensitivity and specificity, 0 is pos in orig data\n",
    "sens = 0\n",
    "sens_tot = 0\n",
    "spec = 0\n",
    "spec_tot = 0\n",
    "for i in range(len(y_pred)):\n",
    "    pred = np.round(y_pred[i])\n",
    "    tru = np.round(Ytestb[i])\n",
    "    # sensitivity: number of correct positives out of all positives\n",
    "    if tru == 0:\n",
    "        sens_tot += 1\n",
    "        if tru == pred:\n",
    "            sens += 1\n",
    "    # specificity: number of correct negatives out of all negatives\n",
    "    elif tru != 1:\n",
    "        spec_tot += 1\n",
    "        if tru != pred:\n",
    "            spec += 1\n",
    "#display both\n",
    "print(f\"Sensitivity: {sens/sens_tot}\")\n",
    "print(f\"Specificity: {spec/spec_tot}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urmom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
