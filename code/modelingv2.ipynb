{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Final Version\n",
    "\n",
    "For this version of my model, I redid the preprocessing to make the images smaller and modify their shape to be compatible with the pretrained inceptionv3 model weights. I also chose to use all of the data rather than scrapping some of it to balance the classes, using ROC-AUC score as my metric of accuracy rather than rote accuracy to account for this imbalance. I then added a few more layers to the base network to train with, most importantly a ```GlobalAveragePooling2D``` layer to better analyze the condensed chunks of information that best correspond to DR according to the literature. I also added some callback functions to the training, including learning rate reduction if we stop improving (measuring improvement using loss decrease), and early training stoppage if the loss decrease goes below a given threshold to make the training process faster. \n",
    "\n",
    "After training the model, this version is already significantly better than the first. Specifically, the model is about 94% accurate with a sensitivity of 95% and a specificity of 93.8% This goes to show the effect of transfer learning for computer vision problems, as taking advantage of an existing network that studies images allows us to fine tune it to look for the conditions we want to learn about rather than spending valuable training time on getting a model that knows how to study images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 16:19:19.850167: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# load data\n",
    "Xtrain = np.load(\"../data/train/Xtrainnew.npy\")\n",
    "Ytrain = np.load(\"../data/train/Ytrainnew.npy\")\n",
    "Xtest = np.load(\"../data/test/Xtestnew.npy\")\n",
    "Ytest = np.load(\"../data/test/Ytestnew.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 16:19:22.707476: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# setup CNN using Inception-v3 (using google JAMA paper for this choice)\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=Xtrain.shape[1:]\n",
    ")\n",
    "\n",
    "# freeze inceptionv3 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add additional layers to iterate on\n",
    "inputs = tf.keras.Input(shape=Xtrain.shape[1:])\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# add some training callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n",
    "# Reducing the Learning Rate if result is not improving. \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "111/111 [==============================] - 52s 450ms/step - loss: 5.6030 - auc: 0.5001 - val_loss: 2.4648 - val_auc: 0.5201 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 49s 440ms/step - loss: 2.2315 - auc: 0.5136 - val_loss: 1.7147 - val_auc: 0.5470 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 49s 440ms/step - loss: 2.0892 - auc: 0.5387 - val_loss: 1.6602 - val_auc: 0.5312 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 49s 439ms/step - loss: 1.8235 - auc: 0.5583 - val_loss: 1.7306 - val_auc: 0.5105 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 1.7123 - auc: 0.5669\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "111/111 [==============================] - 49s 439ms/step - loss: 1.7123 - auc: 0.5669 - val_loss: 1.9146 - val_auc: 0.5301 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 49s 439ms/step - loss: 1.0425 - auc: 0.5905 - val_loss: 1.3382 - val_auc: 0.5239 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 49s 438ms/step - loss: 0.9900 - auc: 0.5993 - val_loss: 1.3464 - val_auc: 0.5235 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 49s 438ms/step - loss: 0.9387 - auc: 0.5937 - val_loss: 1.3285 - val_auc: 0.5075 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.9126 - auc: 0.5968 - val_loss: 1.3526 - val_auc: 0.5154 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 0.9209 - auc: 0.5925\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "111/111 [==============================] - 49s 446ms/step - loss: 0.9209 - auc: 0.5925 - val_loss: 1.3509 - val_auc: 0.5205 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 49s 442ms/step - loss: 0.8618 - auc: 0.6076 - val_loss: 1.3143 - val_auc: 0.5194 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.8478 - auc: 0.6125 - val_loss: 1.2954 - val_auc: 0.5182 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 49s 444ms/step - loss: 0.8455 - auc: 0.6074 - val_loss: 1.3053 - val_auc: 0.5130 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.8482 - auc: 0.6074 - val_loss: 1.2906 - val_auc: 0.5136 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 49s 443ms/step - loss: 0.8461 - auc: 0.6089 - val_loss: 1.2936 - val_auc: 0.5160 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - ETA: 0s - loss: 0.8401 - auc: 0.6186\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "111/111 [==============================] - 49s 442ms/step - loss: 0.8401 - auc: 0.6186 - val_loss: 1.2931 - val_auc: 0.5142 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 49s 441ms/step - loss: 0.8344 - auc: 0.6101 - val_loss: 1.2910 - val_auc: 0.5164 - lr: 1.0000e-06\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2c0bb0cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.AUC()])\n",
    "model.fit(x=Xtrain, y=Ytrain, epochs=20, validation_data=(Xtest, Ytest), callbacks = [early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887/887 [==============================] - 21s 23ms/step\n",
      "0.9402480270574972\n"
     ]
    }
   ],
   "source": [
    "# raw accuracy\n",
    "y_pred = model.predict(Xtest, batch_size=1)\n",
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if np.round(y_pred[i]) == np.round(Ytest[i]):\n",
    "        accuracy += 1\n",
    "print(1-(accuracy/len(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887/887 [==============================] - 21s 24ms/step\n",
      "accuracy: 0.9402480270574972\n",
      "Sensitivity: 0.950354609929078\n",
      "Specificity: 0.938337801608579\n"
     ]
    }
   ],
   "source": [
    "# raw accuracy\n",
    "y_pred = model.predict(Xtest, batch_size=1)\n",
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if np.round(y_pred[i]) == np.round(Ytest[i]):\n",
    "        accuracy += 1\n",
    "print(f\"accuracy: {1-(accuracy/len(y_pred))}\")\n",
    "\n",
    "# get sensitivity and specificity, 0 is pos in orig data\n",
    "sens = 0\n",
    "sens_tot = 0\n",
    "spec = 0\n",
    "spec_tot = 0\n",
    "for i in range(len(y_pred)):\n",
    "    pred = np.round(y_pred[i])\n",
    "    tru = np.round(Ytest[i])\n",
    "    # sensitivity: number of correct positives out of all positives\n",
    "    if tru == 0:\n",
    "        sens_tot += 1\n",
    "        if tru != pred:\n",
    "            sens += 1\n",
    "    # specificity: number of correct negatives out of all negatives\n",
    "    elif tru == 1:\n",
    "        spec_tot += 1\n",
    "        if tru != pred:\n",
    "            spec += 1\n",
    "#display both\n",
    "print(f\"Sensitivity: {sens/sens_tot}\")\n",
    "print(f\"Specificity: {spec/spec_tot}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save(\"../data/saved_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Knowing I want to use transfer learning going forward and still wanting to improve upon my ROC-AUC score, going forward I would modify the type of image preprocessing I would do to see how that would improve my model. I would first want to try working with the images pre-noise reduction (just grayscale and high contrast) to see if there are additional features of interest beyond the veins themselves that my image processing would have eliminated. Additionally, I would want to play around with using different added layer types, consulting more references online for what has worked in solving similar problems in the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urmom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
