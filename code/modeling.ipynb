{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model Attempt\n",
    "\n",
    "For this first model attempt, I trained a convolutional neural network using the InceptionV3 architecture from scratch. I could not use any pretrained weights for this version, as all of my images were fullsize in grayscale, making their dimensions incompatible with the full color versions of the models with pretrained weights. Additionally, in trying to convert the shape to use pretrained weights, my kernel would consistently crash due to the size of the images. I addressed these issues in my second version of the model. In training from scratch, I also decided to use a portion of the dataset rather than the entire thing to create balanced classes. \n",
    "\n",
    "In the end, due to my not modifying the sizes of the input images, the training took an extremely long time. For the sake of time (because this assignment is due in three days), I partially trained the model and found that my AUC score increased from 0.47 to 0.50 after 9 epochs. I expect that with further training that this score would increase, but for the sake of time and wanting to iterate on my model I had to stop here with this version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 08:31:05.762330: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "Xtrain = np.load(\"../data/train/Xtrain.npy\")\n",
    "Ytrain = np.load(\"../data/train/Ytrain.npy\")\n",
    "Xtest = np.load(\"../data/test/Xtest.npy\")\n",
    "Ytest = np.load(\"../data/test/Ytest.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "Ytrain_use = Ytrain[:1124]\n",
    "Xtrain_use = Xtrain[:1124]\n",
    "Ytest_use = Ytest[:282]\n",
    "Xtest_use = Xtest[:282]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert grayscale image to rgb images to make compatible with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image reshaper function to create rgb values for each pixel in the image\n",
    "def img_reshaper(orig_img):\n",
    "    new_img = []\n",
    "    for row in orig_img:\n",
    "        nrow = []\n",
    "        for item in row:\n",
    "            nrow.append([item, item, item])\n",
    "        new_img.append(nrow)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 1124 complete.\n",
      "2 out of 1124 complete.\n",
      "3 out of 1124 complete.\n",
      "4 out of 1124 complete.\n",
      "5 out of 1124 complete.\n",
      "6 out of 1124 complete.\n",
      "7 out of 1124 complete.\n",
      "8 out of 1124 complete.\n",
      "9 out of 1124 complete.\n",
      "10 out of 1124 complete.\n",
      "11 out of 1124 complete.\n",
      "12 out of 1124 complete.\n",
      "13 out of 1124 complete.\n",
      "14 out of 1124 complete.\n",
      "15 out of 1124 complete.\n",
      "16 out of 1124 complete.\n",
      "17 out of 1124 complete.\n",
      "18 out of 1124 complete.\n",
      "19 out of 1124 complete.\n",
      "20 out of 1124 complete.\n",
      "21 out of 1124 complete.\n",
      "22 out of 1124 complete.\n",
      "23 out of 1124 complete.\n",
      "24 out of 1124 complete.\n",
      "25 out of 1124 complete.\n",
      "26 out of 1124 complete.\n",
      "27 out of 1124 complete.\n",
      "28 out of 1124 complete.\n",
      "29 out of 1124 complete.\n",
      "30 out of 1124 complete.\n",
      "31 out of 1124 complete.\n",
      "32 out of 1124 complete.\n",
      "33 out of 1124 complete.\n",
      "34 out of 1124 complete.\n",
      "35 out of 1124 complete.\n",
      "36 out of 1124 complete.\n",
      "37 out of 1124 complete.\n",
      "38 out of 1124 complete.\n",
      "39 out of 1124 complete.\n",
      "40 out of 1124 complete.\n",
      "41 out of 1124 complete.\n",
      "42 out of 1124 complete.\n",
      "43 out of 1124 complete.\n",
      "44 out of 1124 complete.\n",
      "45 out of 1124 complete.\n",
      "46 out of 1124 complete.\n",
      "47 out of 1124 complete.\n",
      "48 out of 1124 complete.\n",
      "49 out of 1124 complete.\n",
      "50 out of 1124 complete.\n",
      "51 out of 1124 complete.\n",
      "52 out of 1124 complete.\n",
      "53 out of 1124 complete.\n",
      "54 out of 1124 complete.\n",
      "55 out of 1124 complete.\n",
      "56 out of 1124 complete.\n",
      "57 out of 1124 complete.\n",
      "58 out of 1124 complete.\n",
      "59 out of 1124 complete.\n",
      "60 out of 1124 complete.\n",
      "61 out of 1124 complete.\n",
      "62 out of 1124 complete.\n",
      "63 out of 1124 complete.\n",
      "64 out of 1124 complete.\n",
      "65 out of 1124 complete.\n",
      "66 out of 1124 complete.\n",
      "67 out of 1124 complete.\n",
      "68 out of 1124 complete.\n",
      "69 out of 1124 complete.\n",
      "70 out of 1124 complete.\n",
      "71 out of 1124 complete.\n",
      "72 out of 1124 complete.\n",
      "73 out of 1124 complete.\n",
      "74 out of 1124 complete.\n",
      "75 out of 1124 complete.\n",
      "76 out of 1124 complete.\n",
      "77 out of 1124 complete.\n",
      "78 out of 1124 complete.\n",
      "79 out of 1124 complete.\n",
      "80 out of 1124 complete.\n",
      "81 out of 1124 complete.\n",
      "82 out of 1124 complete.\n",
      "83 out of 1124 complete.\n",
      "84 out of 1124 complete.\n",
      "85 out of 1124 complete.\n",
      "86 out of 1124 complete.\n",
      "87 out of 1124 complete.\n",
      "88 out of 1124 complete.\n",
      "89 out of 1124 complete.\n",
      "90 out of 1124 complete.\n",
      "91 out of 1124 complete.\n",
      "92 out of 1124 complete.\n",
      "93 out of 1124 complete.\n",
      "94 out of 1124 complete.\n",
      "95 out of 1124 complete.\n",
      "96 out of 1124 complete.\n",
      "97 out of 1124 complete.\n",
      "98 out of 1124 complete.\n",
      "99 out of 1124 complete.\n",
      "100 out of 1124 complete.\n",
      "101 out of 1124 complete.\n",
      "102 out of 1124 complete.\n",
      "103 out of 1124 complete.\n",
      "104 out of 1124 complete.\n",
      "105 out of 1124 complete.\n",
      "106 out of 1124 complete.\n",
      "107 out of 1124 complete.\n",
      "108 out of 1124 complete.\n",
      "109 out of 1124 complete.\n",
      "110 out of 1124 complete.\n",
      "111 out of 1124 complete.\n",
      "112 out of 1124 complete.\n",
      "113 out of 1124 complete.\n",
      "114 out of 1124 complete.\n",
      "115 out of 1124 complete.\n",
      "116 out of 1124 complete.\n",
      "117 out of 1124 complete.\n",
      "118 out of 1124 complete.\n",
      "119 out of 1124 complete.\n",
      "120 out of 1124 complete.\n",
      "121 out of 1124 complete.\n",
      "122 out of 1124 complete.\n"
     ]
    }
   ],
   "source": [
    "# reshape Xtrain\n",
    "Xtrain_temp = []\n",
    "c = 1\n",
    "for img in Xtrain_use:\n",
    "    Xtrain_temp.append(img_reshaper(img))\n",
    "    print(f\"{c} out of 1124 complete.\")\n",
    "    c+=1\n",
    "Xtrain_new = np.array(Xtrain_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape for correctness\n",
    "Xtrain_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save modified Xtrain and Ytrain\n",
    "np.save(\"../data/train/Xtrain_final.npy\", Xtrain_new)\n",
    "np.save(\"../data/train/Ytrain_final.npy\", Ytrain_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape Xtest\n",
    "Xtest_temp = []\n",
    "c = 1\n",
    "for img in Xtest_use:\n",
    "    Xtest_temp.append(img_reshaper(img))\n",
    "    print(f\"{c} out of 1124 complete.\")\n",
    "    c+=1\n",
    "Xtest_new = np.array(Xtrain_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape for correctness\n",
    "Xtest_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save modified Xtest and Ytest\n",
    "np.save(\"../data/train/Xtest_final.npy\", Xtest_new)\n",
    "np.save(\"../data/train/Ytest_final.npy\", Ytest_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 08:31:16.317359: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# setup CNN using Inception-v3 (using google JAMA paper for this choice)\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(Xtrain_use.shape[1],Xtrain_use.shape[2],1)\n",
    ")\n",
    "\n",
    "base_model.load_weights('/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "#base_model = PTModel(input_shape =  t_x.shape[1:], include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new model that we are going to iterate on\n",
    "inputs = tf.keras.Input(shape=(1776, 2368))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 4641s 129s/step - loss: 0.7012 - auc: 0.4907 - accuracy: 0.0000e+00 - val_loss: 0.6934 - val_auc: 0.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      " 9/36 [======>.......................] - ETA: 1:17:35 - loss: 0.6944 - auc: 0.4808 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# train!\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.Accuracy()])\n",
    "model.fit(x=Xtrain_use.reshape((Xtrain_use.shape[0],Xtrain_use.shape[1],Xtrain_use.shape[2],1)), y=Ytrain_use, epochs=20, validation_data=(Xtest_use.reshape((Xtest_use.shape[0],Xtrain_use.shape[1],Xtrain_use.shape[2],1)), Ytest_use))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
