{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data setup and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 08:21:10.633199: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "Xtrain = np.load(\"../data/train/Xtrain.npy\")\n",
    "Ytrain = np.load(\"../data/train/Ytrain.npy\")\n",
    "Xtest = np.load(\"../data/test/Xtest.npy\")\n",
    "Ytest = np.load(\"../data/test/Ytest.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "Ytrain_use = Ytrain[:1124]\n",
    "Xtrain_use = Xtrain[:1124]\n",
    "Ytest_use = Ytest[:282]\n",
    "Xtest_use = Xtest[:282]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert grayscale image to rgb images to make compatible with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image reshaper function to create rgb values for each pixel in the image\n",
    "def img_reshaper(orig_img):\n",
    "    new_img = []\n",
    "    for row in orig_img:\n",
    "        nrow = []\n",
    "        for item in row:\n",
    "            nrow.append([item, item, item])\n",
    "        new_img.append(nrow)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 1124 complete.\n",
      "2 out of 1124 complete.\n",
      "3 out of 1124 complete.\n",
      "4 out of 1124 complete.\n",
      "5 out of 1124 complete.\n",
      "6 out of 1124 complete.\n",
      "7 out of 1124 complete.\n",
      "8 out of 1124 complete.\n",
      "9 out of 1124 complete.\n",
      "10 out of 1124 complete.\n",
      "11 out of 1124 complete.\n",
      "12 out of 1124 complete.\n",
      "13 out of 1124 complete.\n",
      "14 out of 1124 complete.\n",
      "15 out of 1124 complete.\n",
      "16 out of 1124 complete.\n",
      "17 out of 1124 complete.\n",
      "18 out of 1124 complete.\n",
      "19 out of 1124 complete.\n",
      "20 out of 1124 complete.\n",
      "21 out of 1124 complete.\n",
      "22 out of 1124 complete.\n",
      "23 out of 1124 complete.\n",
      "24 out of 1124 complete.\n",
      "25 out of 1124 complete.\n",
      "26 out of 1124 complete.\n",
      "27 out of 1124 complete.\n",
      "28 out of 1124 complete.\n",
      "29 out of 1124 complete.\n",
      "30 out of 1124 complete.\n",
      "31 out of 1124 complete.\n",
      "32 out of 1124 complete.\n",
      "33 out of 1124 complete.\n",
      "34 out of 1124 complete.\n",
      "35 out of 1124 complete.\n",
      "36 out of 1124 complete.\n",
      "37 out of 1124 complete.\n",
      "38 out of 1124 complete.\n",
      "39 out of 1124 complete.\n",
      "40 out of 1124 complete.\n",
      "41 out of 1124 complete.\n",
      "42 out of 1124 complete.\n",
      "43 out of 1124 complete.\n",
      "44 out of 1124 complete.\n",
      "45 out of 1124 complete.\n",
      "46 out of 1124 complete.\n",
      "47 out of 1124 complete.\n",
      "48 out of 1124 complete.\n",
      "49 out of 1124 complete.\n",
      "50 out of 1124 complete.\n",
      "51 out of 1124 complete.\n",
      "52 out of 1124 complete.\n",
      "53 out of 1124 complete.\n",
      "54 out of 1124 complete.\n",
      "55 out of 1124 complete.\n",
      "56 out of 1124 complete.\n",
      "57 out of 1124 complete.\n",
      "58 out of 1124 complete.\n",
      "59 out of 1124 complete.\n",
      "60 out of 1124 complete.\n",
      "61 out of 1124 complete.\n",
      "62 out of 1124 complete.\n",
      "63 out of 1124 complete.\n",
      "64 out of 1124 complete.\n",
      "65 out of 1124 complete.\n",
      "66 out of 1124 complete.\n",
      "67 out of 1124 complete.\n",
      "68 out of 1124 complete.\n",
      "69 out of 1124 complete.\n",
      "70 out of 1124 complete.\n",
      "71 out of 1124 complete.\n",
      "72 out of 1124 complete.\n",
      "73 out of 1124 complete.\n",
      "74 out of 1124 complete.\n",
      "75 out of 1124 complete.\n",
      "76 out of 1124 complete.\n",
      "77 out of 1124 complete.\n",
      "78 out of 1124 complete.\n",
      "79 out of 1124 complete.\n",
      "80 out of 1124 complete.\n",
      "81 out of 1124 complete.\n",
      "82 out of 1124 complete.\n",
      "83 out of 1124 complete.\n",
      "84 out of 1124 complete.\n",
      "85 out of 1124 complete.\n",
      "86 out of 1124 complete.\n",
      "87 out of 1124 complete.\n",
      "88 out of 1124 complete.\n",
      "89 out of 1124 complete.\n",
      "90 out of 1124 complete.\n",
      "91 out of 1124 complete.\n",
      "92 out of 1124 complete.\n",
      "93 out of 1124 complete.\n",
      "94 out of 1124 complete.\n",
      "95 out of 1124 complete.\n",
      "96 out of 1124 complete.\n",
      "97 out of 1124 complete.\n",
      "98 out of 1124 complete.\n",
      "99 out of 1124 complete.\n",
      "100 out of 1124 complete.\n",
      "101 out of 1124 complete.\n",
      "102 out of 1124 complete.\n",
      "103 out of 1124 complete.\n",
      "104 out of 1124 complete.\n",
      "105 out of 1124 complete.\n",
      "106 out of 1124 complete.\n",
      "107 out of 1124 complete.\n",
      "108 out of 1124 complete.\n",
      "109 out of 1124 complete.\n",
      "110 out of 1124 complete.\n",
      "111 out of 1124 complete.\n",
      "112 out of 1124 complete.\n",
      "113 out of 1124 complete.\n",
      "114 out of 1124 complete.\n",
      "115 out of 1124 complete.\n",
      "116 out of 1124 complete.\n",
      "117 out of 1124 complete.\n",
      "118 out of 1124 complete.\n",
      "119 out of 1124 complete.\n",
      "120 out of 1124 complete.\n",
      "121 out of 1124 complete.\n",
      "122 out of 1124 complete.\n"
     ]
    }
   ],
   "source": [
    "# reshape Xtrain\n",
    "Xtrain_temp = []\n",
    "c = 1\n",
    "for img in Xtrain_use:\n",
    "    Xtrain_temp.append(img_reshaper(img))\n",
    "    print(f\"{c} out of 1124 complete.\")\n",
    "    c+=1\n",
    "Xtrain_new = np.array(Xtrain_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape for correctness\n",
    "Xtrain_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save modified Xtrain and Ytrain\n",
    "np.save(\"../data/train/Xtrain_final.npy\", Xtrain_new)\n",
    "np.save(\"../data/train/Ytrain_final.npy\", Ytrain_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape Xtest\n",
    "Xtest_temp = []\n",
    "c = 1\n",
    "for img in Xtest_use:\n",
    "    Xtest_temp.append(img_reshaper(img))\n",
    "    print(f\"{c} out of 1124 complete.\")\n",
    "    c+=1\n",
    "Xtest_new = np.array(Xtrain_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape for correctness\n",
    "Xtest_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save modified Xtest and Ytest\n",
    "np.save(\"../data/train/Xtest_final.npy\", Xtest_new)\n",
    "np.save(\"../data/train/Ytest_final.npy\", Ytest_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 08:21:31.861689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# setup CNN using Inception-v3 (using google JAMA paper for this choice)\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(Xtrain_use.shape[1],Xtrain_use.shape[2],1)\n",
    ")\n",
    "\n",
    "#base_model = PTModel(input_shape =  t_x.shape[1:], include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze the base model\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new model that we are going to iterate on\n",
    "inputs = tf.keras.Input(shape=(1776, 2368))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# train!\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.Accuracy()])\n",
    "model.fit(x=Xtrain_use.reshape((Xtrain_use.shape[0],Xtrain_use.shape[1],Xtrain_use.shape[2],1)), y=Ytrain_use, epochs=20, validation_data=(Xtest_use.reshape((Xtest_use.shape[0],Xtrain_use.shape[1],Xtrain_use.shape[2],1)), Ytest_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modeling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 19:32:13.119314: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The layer inception_v3 has never been called and thus has no defined output shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m base_pretrained_model \u001b[39m=\u001b[39m PTModel(input_shape \u001b[39m=\u001b[39m  (Xtrain_use\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],Xtrain_use\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m],\u001b[39m1\u001b[39m), include_top \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, weights \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m base_pretrained_model\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m pt_depth \u001b[39m=\u001b[39m base_pretrained_model\u001b[39m.\u001b[39;49mget_output_shape_at(\u001b[39m0\u001b[39;49m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     10\u001b[0m pt_features \u001b[39m=\u001b[39m base_pretrained_model(in_lay)\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m BatchNormalization\n",
      "File \u001b[0;32m/opt/anaconda3/envs/urmom/lib/python3.10/site-packages/keras/engine/base_layer.py:1965\u001b[0m, in \u001b[0;36mLayer.get_output_shape_at\u001b[0;34m(self, node_index)\u001b[0m\n\u001b[1;32m   1948\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m   1949\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_output_shape_at\u001b[39m(\u001b[39mself\u001b[39m, node_index):\n\u001b[1;32m   1950\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Retrieves the output shape(s) of a layer at a given node.\u001b[39;00m\n\u001b[1;32m   1951\u001b[0m \n\u001b[1;32m   1952\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1963\u001b[0m \u001b[39m      RuntimeError: If called in Eager mode.\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_attribute_at_index(\n\u001b[1;32m   1966\u001b[0m         node_index, \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39moutput shape\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m   1967\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/urmom/lib/python3.10/site-packages/keras/engine/base_layer.py:2900\u001b[0m, in \u001b[0;36mLayer._get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[1;32m   2878\u001b[0m \n\u001b[1;32m   2879\u001b[0m \u001b[39mThis is used to implement the methods:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2897\u001b[0m \u001b[39m    ValueError: If the index provided does not match any node.\u001b[39;00m\n\u001b[1;32m   2898\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2899\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inbound_nodes:\n\u001b[0;32m-> 2900\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2901\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe layer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m has never been called \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2902\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand thus has no defined \u001b[39m\u001b[39m{\u001b[39;00mattr_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2903\u001b[0m     )\n\u001b[1;32m   2904\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inbound_nodes) \u001b[39m>\u001b[39m node_index:\n\u001b[1;32m   2905\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2906\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAsked to get \u001b[39m\u001b[39m{\u001b[39;00mattr_name\u001b[39m}\u001b[39;00m\u001b[39m at node \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2907\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnode_index\u001b[39m}\u001b[39;00m\u001b[39m, but the layer has only \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2908\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inbound_nodes)\u001b[39m}\u001b[39;00m\u001b[39m inbound nodes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2909\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The layer inception_v3 has never been called and thus has no defined output shape."
     ]
    }
   ],
   "source": [
    "#from keras.applications.vgg16 import VGG16 as PTModel\n",
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2 as PTModel\n",
    "from keras.applications.inception_v3 import InceptionV3 as PTModel\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\n",
    "from keras.models import Model\n",
    "in_lay = Input((Xtrain_use.shape[1],Xtrain_use.shape[2],1))\n",
    "base_pretrained_model = PTModel(input_shape =  (Xtrain_use.shape[1],Xtrain_use.shape[2],1), include_top = False, weights = None)\n",
    "base_pretrained_model.trainable = False\n",
    "pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "pt_features = base_pretrained_model(in_lay)\n",
    "from keras.layers import BatchNormalization\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "\n",
    "# here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "\n",
    "attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(1, \n",
    "                    kernel_size = (1,1), \n",
    "                    padding = 'valid', \n",
    "                    activation = 'sigmoid')(attn_layer)\n",
    "# fan it out to all of the channels\n",
    "up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n",
    "               activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "up_c2.trainable = False\n",
    "attn_layer = up_c2(attn_layer)\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.25)(gap)\n",
    "dr_steps = Dropout(0.25)(Dense(128, activation = 'relu')(gap_dr))\n",
    "out_layer = Dense(t_y.shape[-1], activation = 'softmax')(dr_steps)\n",
    "retina_model = Model(inputs = [in_lay], outputs = [out_layer])\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "def top_2_accuracy(in_gt, in_pred):\n",
    "    return top_k_categorical_accuracy(in_gt, in_pred, k=2)\n",
    "\n",
    "retina_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "                           metrics = ['categorical_accuracy', top_2_accuracy])\n",
    "retina_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
