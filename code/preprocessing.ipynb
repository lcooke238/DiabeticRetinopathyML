{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline\n",
    "\n",
    "This is a pipeline that I modified for the second version of my model, where I wanted to work with smaller images, preserve the desired image shape where each pixel is represented by three color values, and remove any unnecessary noise from my images. Building on my work from the ```exploration.ipynb``` notebook, I discovered that the features of these retinal scans were most visible after converting the images to grayscale, increasing contrast using the ```equalizeHist``` function, and removing noise using a gaussian blur and separating the features of interest from the noise that the blur indicated. I also chose to further increase contrast using an adaptive thresholding function to make the veins in the image more prominent. \n",
    "\n",
    "After abstracting these image modifications to a function, I then applied the function to all of the images in the dataset and saved the output to use later in case any part of the pipeline broke as I continued working. From there, I did an 80-20 train-test split of the images to follow the spec, splitting each class proportionally to ensure that both the training and the testing sets have proportional amounts of each class to work with. I then saved the split data to pickled numpy files to use for modeling. \n",
    "\n",
    "## From the Spec:\n",
    "Referencebale retinopathy folders (Class 1): ('03 Moderate NPDR', '04 Severe NPDR',\n",
    "'05 PDR', '06 Mild NPDR, with DME', '07 Moderate NPDR, with DME', '08 Severe NPDR,\n",
    "with DME', '09 PDR, with DME');\n",
    "- Non-referenceable folders (Class 2): (â€˜01 No DR', '02 Mild NPDR')\n",
    "- Ignore folders: '00 5-Field Images', '10 Ungradable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2 #opencv-python\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split #scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_reshaper(orig_img: 2d image array): given an array of shape (x,y) representing an image\n",
    "    # where each pixel is represented by a single value, produces an array of shape (x,y,3)\n",
    "    # where each pixel is represented by a triple of identical values\n",
    "def img_reshaper(orig_img):\n",
    "    new_img = []\n",
    "    for row in orig_img:\n",
    "        nrow = []\n",
    "        for item in row:\n",
    "            nrow.append([item, item, item])\n",
    "        new_img.append(nrow)\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess(img: string): given filepath img to an image, returns the preprocessed cv2 image object\n",
    "    # throws invalidArgument error if img is not a valid path\n",
    "def Preprocess(img):\n",
    "    try:\n",
    "        i = cv2.imread(img)\n",
    "        small = cv2.resize(i, (150,150))\n",
    "        img_gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
    "        img_hcontrast = cv2.equalizeHist(img_gray)\n",
    "        blur = cv2.GaussianBlur(img_hcontrast, (0,0), sigmaX=33, sigmaY=33)\n",
    "        divide = cv2.divide(img_hcontrast, blur, scale=255)\n",
    "        th3 = cv2.adaptiveThreshold(divide,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "        shaped = img_reshaper(th3)\n",
    "        return shaped\n",
    "    except:\n",
    "        raise ValueError(f\"input {img} is not a valid filepath.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting directory 06\n",
      "starting directory 05\n",
      "starting directory 01\n",
      "starting directory 07\n",
      "starting directory 03\n",
      "starting directory 09\n",
      "starting directory 10\n",
      "starting directory 00\n",
      "starting directory 02\n",
      "starting directory 08\n",
      "starting directory 04\n"
     ]
    }
   ],
   "source": [
    "# initialize data\n",
    "ref_imgs = []\n",
    "nonref_imgs = []\n",
    "\n",
    "# iterate through all images in dataset\n",
    "data_dir = os.path.join(os.getcwd(), \"../data/SAUNAR/\")\n",
    "img_dirs = [name for name in os.listdir(data_dir) if os.path.isdir(data_dir + name)]\n",
    "for d in img_dirs:\n",
    "    print(f\"starting directory {d[:2]}\")\n",
    "    # process and store nonref images from the 01 and 02 folders\n",
    "    if d[:2] == \"01\" or d[:2] == \"02\":\n",
    "        for i in os.listdir(data_dir + d):\n",
    "            nonref_imgs.append(Preprocess(os.path.join(data_dir + d,i)))\n",
    "    # pass on non-classifiable images from 00 and 10 folders\n",
    "    elif d[:2] == \"00\" or d[:2] == \"10\":\n",
    "        pass\n",
    "    # process and store ref images from all other folders\n",
    "    else:\n",
    "        for i in os.listdir(data_dir + d):\n",
    "            ref_imgs.append(Preprocess(os.path.join(data_dir + d,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed image data to file\n",
    "np.save(\"../data/processed/ref_imgsn.npy\", ref_imgs)\n",
    "np.save(\"../data/processed/nonref_imgsn.npy\", nonref_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed image data for splitting\n",
    "ref_imgs_load = np.load(\"../data/processed/ref_imgsn.npy\")\n",
    "nonref_imgs_load = np.load(\"../data/processed/nonref_imgsn.npy\")\n",
    "\n",
    "# train test split\n",
    "Xref_train, Xref_test, yref_train, yref_test = train_test_split(ref_imgs_load, np.zeros(len(ref_imgs_load)), test_size=.2)\n",
    "Xnref_train, Xnref_test, ynref_train, ynref_test = train_test_split(nonref_imgs_load, np.ones(len(nonref_imgs_load)), test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine arrays for both classes to produce final split arrays\n",
    "Xtrain = np.concatenate((Xref_train, Xnref_train))\n",
    "Ytrain = np.concatenate((yref_train, ynref_train))\n",
    "Xtest = np.concatenate((Xref_test, Xnref_test))\n",
    "Ytest = np.concatenate((yref_test, ynref_test))\n",
    "\n",
    "# save split to files for modeling\n",
    "np.save(\"../data/test/Xtestnew.npy\", Xtest)\n",
    "np.save(\"../data/test/Ytestnew.npy\", Ytest)\n",
    "np.save(\"../data/train/Xtrainnew.npy\", Xtrain)\n",
    "np.save(\"../data/train/Ytrainnew.npy\", Ytrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
