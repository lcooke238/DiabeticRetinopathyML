{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 Model with Class Balancing via undersampling\n",
    "\n",
    "For this, I used the exact same model build and process as in version 2, however I used a training set with completely balanced classes by removing any extra samples\n",
    "\n",
    "Note that this method of class balancing does not guarantee an even spread of the subclassess, which could mess with the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 10:40:01.445130: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# load data\n",
    "Xtrain = np.load(\"../data/train/Xtrainnew.npy\")\n",
    "Ytrain = np.load(\"../data/train/Ytrainnew.npy\")\n",
    "Xtest = np.load(\"../data/test/Xtestnew.npy\")\n",
    "Ytest = np.load(\"../data/test/Ytestnew.npy\")\n",
    "\n",
    "# undersample for even class balance\n",
    "Ytrain_use = Ytrain[:1124]\n",
    "Xtrain_use = Xtrain[:1124]\n",
    "Ytest_use = Ytest[:282]\n",
    "Xtest_use = Xtest[:282]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 10:40:07.856307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# setup CNN using Inception-v3 (using google JAMA paper for this choice)\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=Xtrain.shape[1:]\n",
    ")\n",
    "\n",
    "# freeze inceptionv3 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add additional layers to iterate on\n",
    "inputs = tf.keras.Input(shape=Xtrain.shape[1:])\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x) #sumarizing feature existence rather than location\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# add some training callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n",
    "# Reducing the Learning Rate if result is not improving. \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 20s 464ms/step - loss: 3.5869 - auc_1: 0.5667 - val_loss: 2.1707 - val_auc_1: 0.5446 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 17s 465ms/step - loss: 1.4605 - auc_1: 0.6529 - val_loss: 2.0496 - val_auc_1: 0.5289 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 17s 474ms/step - loss: 1.0970 - auc_1: 0.6749 - val_loss: 2.0814 - val_auc_1: 0.5369 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0666 - auc_1: 0.6896\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "36/36 [==============================] - 16s 453ms/step - loss: 1.0666 - auc_1: 0.6896 - val_loss: 2.7954 - val_auc_1: 0.5226 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 16s 454ms/step - loss: 1.0054 - auc_1: 0.6887 - val_loss: 1.9704 - val_auc_1: 0.5514 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 16s 458ms/step - loss: 0.7820 - auc_1: 0.7221 - val_loss: 1.9693 - val_auc_1: 0.5327 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 17s 463ms/step - loss: 0.7648 - auc_1: 0.7307 - val_loss: 2.0012 - val_auc_1: 0.5321 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.7520 - auc_1: 0.7361 - val_loss: 1.9675 - val_auc_1: 0.5331 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 16s 457ms/step - loss: 0.7598 - auc_1: 0.7374 - val_loss: 1.9611 - val_auc_1: 0.5373 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 17s 462ms/step - loss: 0.7476 - auc_1: 0.7471 - val_loss: 2.0063 - val_auc_1: 0.5379 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.8297 - auc_1: 0.7164\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "36/36 [==============================] - 17s 465ms/step - loss: 0.8297 - auc_1: 0.7164 - val_loss: 1.9727 - val_auc_1: 0.5317 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 16s 458ms/step - loss: 0.7000 - auc_1: 0.7516 - val_loss: 1.9885 - val_auc_1: 0.5411 - lr: 1.0000e-05\n",
      "Epoch 12: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f951ac0b8b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.AUC()]) \n",
    "#AUC: represents the probability that a random positive (green) example is positioned to the right of a random negative (red) example\n",
    "model.fit(x=Xtrain_use, y=Ytrain_use, epochs=20, validation_data=(Xtest_use, Ytest_use), callbacks = [early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/saved_model_balanced/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/saved_model_balanced/assets\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save(\"../data/saved_model_balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887/887 [==============================] - 22s 23ms/step\n",
      "accuracy: 0.9143179255918827\n",
      "Sensitivity: 0.9290780141843972\n",
      "Specificity: 0.9115281501340483\n"
     ]
    }
   ],
   "source": [
    "# raw accuracy\n",
    "y_pred = model.predict(Xtest, batch_size=1)\n",
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if np.round(y_pred[i]) == np.round(Ytest[i]):\n",
    "        accuracy += 1\n",
    "print(f\"accuracy: {1-(accuracy/len(y_pred))}\")\n",
    "\n",
    "# get sensitivity and specificity, 0 is pos in orig data\n",
    "sens = 0\n",
    "sens_tot = 0\n",
    "spec = 0\n",
    "spec_tot = 0\n",
    "for i in range(len(y_pred)):\n",
    "    pred = np.round(y_pred[i])\n",
    "    tru = np.round(Ytest[i])\n",
    "    # sensitivity: number of correct positives out of all positives\n",
    "    if tru == 0:\n",
    "        sens_tot += 1\n",
    "        if tru != pred:\n",
    "            sens += 1\n",
    "    # specificity: number of correct negatives out of all negatives\n",
    "    elif tru == 1:\n",
    "        spec_tot += 1\n",
    "        if tru != pred:\n",
    "            spec += 1\n",
    "#display both\n",
    "print(f\"Sensitivity: {sens/sens_tot}\")\n",
    "print(f\"Specificity: {spec/spec_tot}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Knowing I want to use transfer learning going forward and still wanting to improve upon my ROC-AUC score, going forward I would play with the type of image preprocessing I would do and the layers that I added on top of InceptionV3 to see how that would improve my model. Some ideas include additional noise reduction on my images, as the final images still contain a lot of gray fuzz. Additionally, I would want to play around with using different added layer types in addition to the Global Pooling, consulting more references online for what has worked in solving similar problems in the past.\n",
    "\n",
    "Additionally, overfitting and class imbalance problems are still a potential issue here. While I do already implement early stopping for overfitting, I would want to try playing with larger learning rates to see if I can do any better. For the class imbalance issue, I would also want to try training a model on undersampled data (taking a proportional number of images from each subclass for a representative sample) with an even class distribution to judge its performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urmom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
